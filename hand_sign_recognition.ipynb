{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f61b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tisha Verma\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c58bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure TensorFlow to be less verbose and use memory more efficiently\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce TensorFlow logging verbosity\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddb3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_PATH = 'hand_sign_model.h5'\n",
    "IMAGE_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e1daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the class labels\n",
    "def load_labels(dataset_path):\n",
    "    try:\n",
    "        return sorted(os.listdir(dataset_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading labels: {e}\")\n",
    "        # Fallback to alphabet if dataset path is invalid\n",
    "        return [chr(i) for i in range(ord('A'), ord('Z')+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976ae678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create model\n",
    "def get_model(dataset_path=None, force_train=False):\n",
    "    \"\"\"\n",
    "    Load existing model or train a new one if needed\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to training data (required only for training)\n",
    "        force_train: Whether to force training even if model exists\n",
    "        \n",
    "    Returns:\n",
    "        model: Loaded or trained TensorFlow model\n",
    "        labels: List of class labels\n",
    "    \"\"\"\n",
    "    # Try to load labels first\n",
    "    if dataset_path:\n",
    "        labels = load_labels(dataset_path)\n",
    "    else:\n",
    "        # If no dataset path and no existing model, we can't proceed\n",
    "        if not os.path.exists(MODEL_PATH) and not force_train:\n",
    "            raise ValueError(\"No model exists and no dataset provided for training\")\n",
    "        # Try to infer labels from alphabet (A-Z)\n",
    "        labels = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "    \n",
    "    # Check if model already exists and we're not forcing a retrain\n",
    "    if os.path.exists(MODEL_PATH) and not force_train:\n",
    "        print(f\"Loading existing model from {MODEL_PATH}...\")\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(MODEL_PATH)\n",
    "            print(\"Model loaded successfully!\")\n",
    "            return model, labels\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            if not dataset_path:\n",
    "                raise ValueError(\"Failed to load model and no dataset provided for training\")\n",
    "            print(\"Will train a new model instead.\")\n",
    "    \n",
    "    # If we get here, we need to train a new model\n",
    "    if not dataset_path:\n",
    "        raise ValueError(\"Dataset path is required for training\")\n",
    "    \n",
    "    print(f\"Training new model with data from {dataset_path}...\")\n",
    "    from tensorflow.keras import layers, models\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    \n",
    "    # Train the model from scratch\n",
    "    model = train_model(dataset_path, labels)\n",
    "    return model, labels\n",
    "\n",
    "# Function to train the model (called by get_model when needed)\n",
    "def train_model(dataset_path, labels):\n",
    "    \"\"\"Train a new hand sign recognition model\"\"\"\n",
    "    from tensorflow.keras import layers, models\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    \n",
    "    # Data loading\n",
    "    print(\"Loading training data...\")\n",
    "    data = []\n",
    "    target = []\n",
    "    \n",
    "    # Track progress\n",
    "    total_classes = len(labels)\n",
    "    \n",
    "    for label_idx, label in enumerate(labels):\n",
    "        label_path = os.path.join(dataset_path, label)\n",
    "        print(f\"Processing class {label} ({label_idx+1}/{total_classes})\")\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Directory not found for class {label}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        for img_name in os.listdir(label_path):\n",
    "            try:\n",
    "                img_path = os.path.join(label_path, img_name)\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                    \n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "                image = image / 255.0  # Normalize\n",
    "                data.append(image)\n",
    "                target.append(label_idx)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(data)} images across {total_classes} classes\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    data = np.array(data)\n",
    "    target_array = np.array(target)\n",
    "    target = to_categorical(target_array, num_classes=len(labels))\n",
    "    \n",
    "    # Split data\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data, target, test_size=0.2, random_state=42, stratify=target_array\n",
    "    )\n",
    "    \n",
    "    print(f\"Training with {len(x_train)} images, validating with {len(x_val)} images\")\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Sequential([\n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(len(labels), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        patience=3, \n",
    "        min_lr=0.0001\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Starting training for up to 15 epochs...\")\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=15,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    val_loss, val_acc = model.evaluate(x_val, y_val)\n",
    "    print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    model.save(MODEL_PATH)\n",
    "    print(f\"Model saved to {MODEL_PATH}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c294750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_hand_sign(model, image, labels):\n",
    "    \"\"\"\n",
    "    Predict hand sign from image\n",
    "    \n",
    "    Args:\n",
    "        model: Trained TensorFlow model\n",
    "        image: OpenCV image (BGR format)\n",
    "        labels: List of class labels\n",
    "        \n",
    "    Returns:\n",
    "        prediction: Predicted class name\n",
    "        confidence: Confidence score (0-100%)\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    resized_img = cv2.resize(image, IMAGE_SIZE)\n",
    "    normalized_img = resized_img / 255.0\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = model.predict(np.expand_dims(normalized_img, axis=0), verbose=0)[0]\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = np.argmax(pred)\n",
    "    confidence = pred[predicted_class] * 100\n",
    "    \n",
    "    return labels[predicted_class], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451b5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam(model, labels):\n",
    "    \"\"\"Run hand sign recognition using OpenCV webcam interface\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    print(\"Starting webcam. Press 'q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "            \n",
    "        # Flip frame for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Draw rectangle for hand placement\n",
    "        h, w = frame.shape[:2]\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        rect_size = min(w, h) // 3\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            frame, \n",
    "            (center_x - rect_size // 2, center_y - rect_size // 2),\n",
    "            (center_x + rect_size // 2, center_y + rect_size // 2),\n",
    "            (0, 255, 0), 2\n",
    "        )\n",
    "        \n",
    "        # Extract hand region for prediction\n",
    "        hand_region = frame[\n",
    "            center_y - rect_size // 2:center_y + rect_size // 2,\n",
    "            center_x - rect_size // 2:center_x + rect_size // 2\n",
    "        ]\n",
    "        \n",
    "        if hand_region.size > 0:\n",
    "            # Add slight delay to avoid constant predictions which can slow down the UI\n",
    "            sign, confidence = predict_hand_sign(model, hand_region, labels)\n",
    "            \n",
    "            # Display prediction on frame\n",
    "            cv2.putText(\n",
    "                frame, \n",
    "                f\"{sign}: {confidence:.1f}%\", \n",
    "                (20, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, (0, 255, 0), 2\n",
    "            )\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Hand Sign Recognition', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca127e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
